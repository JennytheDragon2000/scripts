1
00:00:00,250 --> 00:00:03,422
And one of the local volumes you can use for data

2
00:00:03,476 --> 00:00:06,250
persistence is called hostpath.

3
00:00:06,330 --> 00:00:10,206
And as I said, this is very simple to configure because we

4
00:00:10,228 --> 00:00:14,718
don't need to create storage on a remote platform,

5
00:00:14,884 --> 00:00:18,430
like a cloud platform for example. And this is actually

6
00:00:18,500 --> 00:00:22,010
one of the volume types that is tested in the CKA

7
00:00:22,090 --> 00:00:26,786
exam. So in this lecture we're going to configure a host path volume

8
00:00:26,898 --> 00:00:30,150
for our application. And this is actually very simple.

9
00:00:30,300 --> 00:00:34,134
First, we're going to create a persistent volume component with

10
00:00:34,172 --> 00:00:37,574
the host path as a storage backend. So again,

11
00:00:37,612 --> 00:00:42,198
the data storage with host path is actually local machine.

12
00:00:42,294 --> 00:00:46,038
So on the server's file system we're

13
00:00:46,054 --> 00:00:49,562
going to choose a location which will persist all the data

14
00:00:49,696 --> 00:00:53,402
for our application. Once we have the persistent volume

15
00:00:53,466 --> 00:00:57,418
created in the cluster, we can then create a persistent volume

16
00:00:57,514 --> 00:01:01,038
claim. The persistent volume claim resource is there to

17
00:01:01,124 --> 00:01:04,894
claim storage through persistent volume

18
00:01:04,942 --> 00:01:08,958
component. So again, if we have multiple persistent volumes in the cluster

19
00:01:09,054 --> 00:01:13,186
and we create a volume claim, the claim will actually find the

20
00:01:13,208 --> 00:01:16,962
persistent volume with the most fitting configuration

21
00:01:17,106 --> 00:01:20,838
to claim its storage. And finally, because we want

22
00:01:20,844 --> 00:01:24,722
to use this storage in our application, we are going to configure

23
00:01:24,786 --> 00:01:28,634
our deployment or our pod actually to use

24
00:01:28,672 --> 00:01:32,774
that storage through a persistent volume claim.

25
00:01:32,902 --> 00:01:34,940
So let's see how all that works.

26
00:01:37,550 --> 00:01:41,454
So first of all, how do we create persistent volume? Let's check

27
00:01:41,492 --> 00:01:44,654
if we have option to

28
00:01:44,692 --> 00:01:48,254
create it in an imperative way. And as you see, it's not

29
00:01:48,292 --> 00:01:51,754
actually on the list of create subcommands.

30
00:01:51,882 --> 00:01:55,874
However, you can always check the Kubernetes official documentation for

31
00:01:55,912 --> 00:01:59,662
the example files for Kubernetes resources.

32
00:01:59,806 --> 00:02:03,730
And this one actually documents creating a persistent volume,

33
00:02:04,230 --> 00:02:07,858
a volume claim for it, as well as how to then

34
00:02:08,024 --> 00:02:11,590
use that in a pod. So we're going to use this as a reference.

35
00:02:12,730 --> 00:02:16,422
So I'm going to copy the first three lines and we're going to create

36
00:02:16,476 --> 00:02:19,882
this step by step. And let's call this

37
00:02:20,016 --> 00:02:25,126
Myapp persistent volume Yaml.

38
00:02:25,318 --> 00:02:29,820
And as you see the kind is persistent volume and

39
00:02:30,210 --> 00:02:32,858
let's call it data Pv.

40
00:02:33,034 --> 00:02:36,794
And we have the specification. So what are the main attributes

41
00:02:36,842 --> 00:02:40,174
to define in a persistent volume? The first and the

42
00:02:40,212 --> 00:02:43,742
main configuration is what storage

43
00:02:43,806 --> 00:02:47,234
backend we want to use to store the

44
00:02:47,272 --> 00:02:50,238
data. Is it Amazon's elastic block storage?

45
00:02:50,334 --> 00:02:53,454
Is it Google Cloud storage or some NFS

46
00:02:53,502 --> 00:02:56,870
server, or in our case host path type?

47
00:02:57,020 --> 00:03:00,214
And note that depending on which storage you

48
00:03:00,252 --> 00:03:04,630
use, the attributes will be different. For host path,

49
00:03:05,770 --> 00:03:09,754
the attribute is host path, and then it has its own

50
00:03:09,872 --> 00:03:13,446
set of configuration options. And as I said, host path

51
00:03:13,478 --> 00:03:17,530
configuration is super simple. We just need a path

52
00:03:18,110 --> 00:03:22,314
or basically a location on local machine

53
00:03:22,442 --> 00:03:26,190
which will store the data and we're going to set it to mount

54
00:03:26,610 --> 00:03:30,638
data. And these two lines here will basically configure what

55
00:03:30,724 --> 00:03:34,526
storage backend we're using to store the data when

56
00:03:34,548 --> 00:03:38,686
we reference it using the persistent volume. So once the storage

57
00:03:38,718 --> 00:03:41,922
backend is configured, now we want to know how much

58
00:03:42,056 --> 00:03:45,650
storage do we actually need. So basically we need a storage

59
00:03:45,730 --> 00:03:49,462
capacity that this persistent volume will

60
00:03:49,516 --> 00:03:53,746
require from the type of storage defined

61
00:03:53,778 --> 00:03:57,218
here. So on a local machine on host path,

62
00:03:57,314 --> 00:04:01,162
we want a capacity for

63
00:04:01,216 --> 00:04:04,486
storage of 10gb.

64
00:04:04,598 --> 00:04:08,262
So we know where the data will be stored, we know how much storage

65
00:04:08,326 --> 00:04:11,950
capacity we require for storing the data. And finally

66
00:04:12,100 --> 00:04:16,046
we need to configure what kind of access do we give

67
00:04:16,148 --> 00:04:19,418
the application for this storage. So we're

68
00:04:19,434 --> 00:04:22,350
going to define access modes,

69
00:04:23,430 --> 00:04:26,830
which is a list actually, and we're going to define,

70
00:04:26,910 --> 00:04:30,466
read write once, or we

71
00:04:30,488 --> 00:04:33,714
can define read write many. So depending on

72
00:04:33,832 --> 00:04:37,518
what type of access your application needs to the storage,

73
00:04:37,614 --> 00:04:41,126
whether it needs to write multiple times, whether it only needs a

74
00:04:41,148 --> 00:04:44,854
read only access, et cetera, you can define the access modes right

75
00:04:44,892 --> 00:04:48,266
here. And that will be actually the basic configuration of

76
00:04:48,368 --> 00:04:52,074
a persistent volume and we can

77
00:04:52,192 --> 00:04:53,820
save and apply.

78
00:04:58,590 --> 00:05:02,926
So data PV was created and we can actually get

79
00:05:03,028 --> 00:05:06,442
or list all the persistent volumes using get pv

80
00:05:06,506 --> 00:05:09,546
command. And as you see, the status of this persistent

81
00:05:09,578 --> 00:05:13,330
volume is available, meaning it is not being used

82
00:05:13,400 --> 00:05:16,690
by any application yet, or in other words,

83
00:05:16,760 --> 00:05:18,820
it hasn't been claimed yet.

84
00:05:21,430 --> 00:05:25,242
So now let's go ahead and create a persistent volume claim

85
00:05:25,406 --> 00:05:29,714
that will basically claim the storage that this persistent

86
00:05:29,762 --> 00:05:32,854
volume defines. So I'm going to

87
00:05:32,892 --> 00:05:36,626
create myappBC

88
00:05:36,738 --> 00:05:40,630
YamL and again referencing

89
00:05:40,710 --> 00:05:45,606
the documentation persistent

90
00:05:45,638 --> 00:05:48,822
volume claim kind. And let's say we are configuring

91
00:05:48,886 --> 00:05:52,346
this for a MySQL database pod. So let's

92
00:05:52,378 --> 00:05:56,270
call it MySql data Pvc.

93
00:05:57,490 --> 00:06:01,566
And then we have the specification for the volume claim. First of all,

94
00:06:01,588 --> 00:06:05,186
we want to define how much storage do we want

95
00:06:05,208 --> 00:06:08,942
to claim. Again, remember, persistent volumes and persistent volume

96
00:06:09,006 --> 00:06:12,466
claims are created separately, so we don't know how

97
00:06:12,488 --> 00:06:15,990
many volumes or what kind of volumes are available

98
00:06:16,060 --> 00:06:20,562
in a cluster. Also, we don't care because we are creating a claim

99
00:06:20,706 --> 00:06:24,098
that will automatically find the right storage

100
00:06:24,194 --> 00:06:27,834
or right persistent volume with the right storage to

101
00:06:27,872 --> 00:06:31,478
claim. So basically we define our wishes

102
00:06:31,574 --> 00:06:35,318
for the storage in the volume claim specification

103
00:06:35,494 --> 00:06:39,690
and let it find the matching volume available

104
00:06:39,760 --> 00:06:43,102
in a cluster. The first thing we want to define is

105
00:06:43,156 --> 00:06:46,686
how much storage do we actually need for the application? And we

106
00:06:46,708 --> 00:06:51,070
can define that using resources requests.

107
00:06:52,050 --> 00:06:56,370
So we are requesting storage

108
00:06:56,710 --> 00:06:59,774
of let's say 5gb,

109
00:06:59,902 --> 00:07:03,234
that's how much our application that will use

110
00:07:03,272 --> 00:07:06,854
these volume claim will need. And we also define what type

111
00:07:06,892 --> 00:07:10,438
of access our application needs, again using access

112
00:07:10,524 --> 00:07:11,350
modes.

113
00:07:13,850 --> 00:07:17,926
And let's say our application needs read

114
00:07:18,108 --> 00:07:22,426
write many access, so let's save it.

115
00:07:22,608 --> 00:07:26,410
And now when I apply this

116
00:07:26,480 --> 00:07:27,610
volume claim,

117
00:07:31,810 --> 00:07:35,326
I will expect that it will find a

118
00:07:35,348 --> 00:07:39,274
matching persistent volume that is available in the cluster

119
00:07:39,402 --> 00:07:42,400
and claim that. So let's apply.

120
00:07:43,030 --> 00:07:47,214
And if I check get persistent volume claim

121
00:07:47,262 --> 00:07:50,834
first, we see its details, and if I do

122
00:07:50,952 --> 00:07:54,114
get pv, you see that status changed from

123
00:07:54,152 --> 00:07:57,654
available to bound as well as the

124
00:07:57,692 --> 00:08:01,522
PVC state is bound. And that means that PVC

125
00:08:01,586 --> 00:08:04,994
was created and it was able to find a matching

126
00:08:05,122 --> 00:08:08,314
persistent volume in the cluster. And once it

127
00:08:08,352 --> 00:08:11,242
found it, those two were actually bound together.

128
00:08:11,376 --> 00:08:15,354
And that means that this persistent volume is not available

129
00:08:15,472 --> 00:08:18,934
for any other claim. Now until the persistent

130
00:08:18,982 --> 00:08:22,766
volume claim releases it again. And note that the

131
00:08:22,788 --> 00:08:26,174
persistent volume has a capacity of 10gb of

132
00:08:26,212 --> 00:08:29,370
storage. However, our claim only required

133
00:08:29,530 --> 00:08:33,502
5gb of storage, so the specification

134
00:08:33,566 --> 00:08:37,998
doesn't have to 100% match the persistent volume

135
00:08:38,094 --> 00:08:42,446
configuration. It has to be the best match among

136
00:08:42,558 --> 00:08:44,930
many persistent volumes.

137
00:08:47,450 --> 00:08:51,670
Now we have those two available, and that means we can actually

138
00:08:51,820 --> 00:08:55,766
create our application with the volume claim so that

139
00:08:55,788 --> 00:08:59,318
it can use the storage defined by the persistent volume.

140
00:08:59,414 --> 00:09:06,934
So I'm going to create actually a MySQL deployment yaml

141
00:09:06,982 --> 00:09:11,310
file and paste in a super simple

142
00:09:11,460 --> 00:09:15,086
deployment configuration. Nothing crazy here.

143
00:09:15,188 --> 00:09:19,102
And also we're creating a deployment, not a stateful set, even though it's an application,

144
00:09:19,236 --> 00:09:23,146
because we're just running one replica of the database.

145
00:09:23,258 --> 00:09:26,862
So that's fine. Now with this configuration there is no volume

146
00:09:26,926 --> 00:09:29,730
configured, so let's actually do that. First of all,

147
00:09:29,800 --> 00:09:33,294
you learn that volumes are configured for a pod.

148
00:09:33,422 --> 00:09:36,914
So pod is basically taking the volume

149
00:09:37,042 --> 00:09:40,722
from the volume claim, and that means we define this configuration

150
00:09:40,786 --> 00:09:44,646
on a pod level. So in the specification of

151
00:09:44,668 --> 00:09:49,206
the pod, under the containers, we're going to specify volumes

152
00:09:49,238 --> 00:09:53,402
attribute, and volumes attribute is a list because we can

153
00:09:53,536 --> 00:09:57,654
provide multiple volumes to a pod for different purposes.

154
00:09:57,782 --> 00:10:01,642
So one of them could be for database data, another one

155
00:10:01,696 --> 00:10:05,578
could be for configuration data, et cetera. And the volumes

156
00:10:05,674 --> 00:10:09,850
configuration is pretty easy. We have the name of the volume which we decide

157
00:10:09,930 --> 00:10:13,394
what it's going to be, let's call it DB data.

158
00:10:13,592 --> 00:10:17,970
And here we're going to reference the persistent volume claim.

159
00:10:18,710 --> 00:10:23,474
Again, you can check the syntax in the documentation for

160
00:10:23,592 --> 00:10:26,962
how to reference it. So the attribute is persistent

161
00:10:27,106 --> 00:10:29,190
volume claim,

162
00:10:30,810 --> 00:10:34,022
and under that we have claim name

163
00:10:34,156 --> 00:10:38,086
and this is going to be the name that we gave our persistent volume

164
00:10:38,118 --> 00:10:41,894
claim component, and it's called MySQL

165
00:10:42,022 --> 00:10:45,494
data PvC.

166
00:10:45,622 --> 00:10:50,134
That's what we called it, and that's going to be enough to reference

167
00:10:50,262 --> 00:10:54,126
the volume claim inside the pod. However, once we have

168
00:10:54,148 --> 00:10:57,534
the volume attached to the pod, we actually need to use it

169
00:10:57,572 --> 00:11:00,874
in our application. And the application is running in a container,

170
00:11:00,922 --> 00:11:04,422
so we have to pass that volume to the container.

171
00:11:04,506 --> 00:11:08,494
Again, if we have multiple containers in the pod, you can actually decide

172
00:11:08,622 --> 00:11:12,722
which containers or which applications gets that

173
00:11:12,776 --> 00:11:16,406
volume right. You may just want to give it to the main application,

174
00:11:16,588 --> 00:11:20,454
but not share that volume with the sidecar or

175
00:11:20,492 --> 00:11:23,766
init containers. So to pass the volume configuration to

176
00:11:23,788 --> 00:11:28,490
the container, we have an attribute called volume mounts.

177
00:11:29,150 --> 00:11:31,500
Let's actually give us a space here.

178
00:11:32,110 --> 00:11:35,302
And volume mounts is also an array

179
00:11:35,366 --> 00:11:39,014
because you may have multiple volumes in your pod

180
00:11:39,062 --> 00:11:43,162
and you can pass multiple of those volumes to each container.

181
00:11:43,306 --> 00:11:46,718
And this is also a pretty easy configuration. We have the name

182
00:11:46,884 --> 00:11:51,454
which has to reference one of these volumes here and

183
00:11:51,572 --> 00:11:55,182
the second attribute which is mount path.

184
00:11:55,326 --> 00:11:59,198
And that basically means when we take that storage,

185
00:11:59,374 --> 00:12:03,042
whatever and wherever it is configured, we want to

186
00:12:03,096 --> 00:12:07,234
mount it into the container because the application inside the container

187
00:12:07,282 --> 00:12:10,694
will be the one writing to that storage, right. So we

188
00:12:10,732 --> 00:12:14,390
have to make a copy of that location inside

189
00:12:14,460 --> 00:12:18,326
the container at a certain path, and that's

190
00:12:18,358 --> 00:12:22,182
the mount path. Right. Where are we mounting it? Into the container's

191
00:12:22,246 --> 00:12:25,814
file system. And this could be again any location

192
00:12:25,862 --> 00:12:31,078
you want. In our case, let's define Varlebysql

193
00:12:31,174 --> 00:12:34,334
because that's where the mySQl data is configured and

194
00:12:34,372 --> 00:12:37,806
that's it. It's actually pretty easy to configure volumes in

195
00:12:37,828 --> 00:12:41,786
a pod because you did all the configuration inside the volume

196
00:12:41,818 --> 00:12:45,282
claim and persistent volume itself. So here

197
00:12:45,336 --> 00:12:47,934
you're just referencing that storage.

198
00:12:48,062 --> 00:12:51,550
And as you see, when you're creating pods

199
00:12:51,630 --> 00:12:54,846
or when developers are creating pods and deployments,

200
00:12:55,038 --> 00:12:58,674
they may not even know what kind of storage is configured

201
00:12:58,722 --> 00:13:02,694
behind this volume claim. They may only be interested in the

202
00:13:02,732 --> 00:13:06,626
capacity, so they want 10gb of storage for their database

203
00:13:06,658 --> 00:13:10,346
data and that's it, and that's all they care about. So we have

204
00:13:10,368 --> 00:13:13,546
to configure a root password here as

205
00:13:13,568 --> 00:13:16,954
an environment variable. So let's add env

206
00:13:17,072 --> 00:13:21,166
attribute name will be name of

207
00:13:21,188 --> 00:13:25,614
the environment variable and

208
00:13:25,652 --> 00:13:29,150
let's set it to some hard coded value like my password,

209
00:13:30,130 --> 00:13:33,620
and let's save it.

210
00:13:37,190 --> 00:13:40,706
I'm going to apply and let's see that the pod is

211
00:13:40,808 --> 00:13:44,082
running. Let's check again. We can

212
00:13:44,136 --> 00:13:49,942
also do describe and

213
00:13:49,996 --> 00:13:53,270
make sure that the volumes configuration is correct

214
00:13:53,340 --> 00:13:57,510
here. And we can also enter the pod

215
00:13:58,430 --> 00:14:04,922
using exec command and

216
00:14:04,976 --> 00:14:08,890
check that the mount path was actually created.

217
00:14:09,310 --> 00:14:12,670
And as you see the path was created, it actually

218
00:14:12,740 --> 00:14:16,314
has some data that MySQL application in the container

219
00:14:16,362 --> 00:14:20,538
automatically generates. And this means whatever MySQL generated

220
00:14:20,634 --> 00:14:24,386
right here will be also persisted in the storage backend that we

221
00:14:24,408 --> 00:14:28,510
configured, which in our case is a local storage on the host path,

222
00:14:28,590 --> 00:14:32,754
which we defined to be on the host at

223
00:14:32,952 --> 00:14:35,594
Mount datapath.

224
00:14:35,742 --> 00:14:39,974
Now where can we actually find that actual physical storage for

225
00:14:40,012 --> 00:14:43,286
the host path or on which node is it

226
00:14:43,308 --> 00:14:47,378
actually configured? If we do describe pod again,

227
00:14:47,564 --> 00:14:51,210
we will see which worker node it is actually running on.

228
00:14:51,280 --> 00:14:54,314
So our pod started on worker node one.

229
00:14:54,432 --> 00:14:58,060
So if we ssh to worker one and

230
00:14:58,430 --> 00:15:02,446
check mount data

231
00:15:02,628 --> 00:15:06,590
location here, you will see that what MySQl application

232
00:15:06,740 --> 00:15:10,906
generated inside the container has already been saved

233
00:15:10,938 --> 00:15:14,654
right here. So now when the MySQL container and pod

234
00:15:14,702 --> 00:15:18,514
get removed and all the data inside the container will be

235
00:15:18,552 --> 00:15:22,578
gone, this data will still be persisted on worker one.

236
00:15:22,664 --> 00:15:25,534
So when we restart the pod on worker one,

237
00:15:25,672 --> 00:15:29,574
it will synchronize again the location from here,

238
00:15:29,772 --> 00:15:33,618
from here to its mount path inside the container,

239
00:15:33,714 --> 00:15:37,814
and we'll be able to read in all this data. So that's how

240
00:15:37,932 --> 00:15:41,994
the persistence with host path actually works. However, you probably

241
00:15:42,032 --> 00:15:45,306
already see the disadvantage, which is that the data is

242
00:15:45,328 --> 00:15:49,046
specifically on one worker node. So if the pod

243
00:15:49,078 --> 00:15:52,414
gets scheduled on worker two, for example, the data will not

244
00:15:52,452 --> 00:15:55,758
be here, right? But as I

245
00:15:55,764 --> 00:16:00,458
said, host path is actually great for testing volumes

246
00:16:00,554 --> 00:16:04,754
or for configuring things that are not so important as the

247
00:16:04,792 --> 00:16:08,594
database data. For example, and therefore as the

248
00:16:08,632 --> 00:16:11,726
official Kubernetes documentation also says, you shouldn't

249
00:16:11,758 --> 00:16:15,700
be using hostbeth for the database services,

250
00:16:16,010 --> 00:16:19,574
especially in a production environment. And great thing about having

251
00:16:19,612 --> 00:16:22,882
all these abstractions for volume, like persistent volume

252
00:16:22,946 --> 00:16:26,434
and persistent volume claim and then referencing that claim

253
00:16:26,482 --> 00:16:30,470
in the pod is that whenever you change a storage

254
00:16:30,630 --> 00:16:33,974
type, for example, you change your database storage from host

255
00:16:34,022 --> 00:16:37,814
path to a remote storage. The only thing you will need to update

256
00:16:37,862 --> 00:16:41,674
is persistent volume resource. Everything else will

257
00:16:41,712 --> 00:16:45,486
actually stay the same. The pod will reference the same persistent volume which will

258
00:16:45,508 --> 00:16:49,066
now reference a different data storage in the background.

259
00:16:49,178 --> 00:16:52,910
So you will not have to update your deployments or pods

260
00:16:55,810 --> 00:16:59,662
that we deployed next to the main application needs to

261
00:16:59,716 --> 00:17:03,454
access the log files that application creates in order to

262
00:17:03,572 --> 00:17:06,942
be able to collect them and send them to an external

263
00:17:07,006 --> 00:17:10,914
logging service. And right now it can't because the

264
00:17:10,952 --> 00:17:14,846
main application container has its own file

265
00:17:14,878 --> 00:17:18,526
system and the sidecar container has its

266
00:17:18,568 --> 00:17:22,082
own file system and they cannot access each other's

267
00:17:22,146 --> 00:17:26,230
file systems, so they need a shared location which

268
00:17:26,300 --> 00:17:29,958
both containers can access. However, we don't really care

269
00:17:30,044 --> 00:17:33,574
persisting this log data because the log sidecar

270
00:17:33,622 --> 00:17:37,210
is anyways sending it to some remote log service.

271
00:17:37,360 --> 00:17:40,442
And even if we lose some log data,

272
00:17:40,576 --> 00:17:44,382
let's say we don't really care about that. So basically

273
00:17:44,516 --> 00:17:48,382
in this case, we need to configure a storage that

274
00:17:48,516 --> 00:17:51,646
these two containers can share, but it doesn't have

275
00:17:51,668 --> 00:17:55,162
to be a persistent and permanent

276
00:17:55,226 --> 00:17:59,438
storage. Another use case for this will be if the sidecar container

277
00:17:59,534 --> 00:18:02,994
is updating the application cache, we would need to give

278
00:18:03,032 --> 00:18:06,418
the main application and sidecar applications access

279
00:18:06,504 --> 00:18:10,306
to the same shared storage where the application cache

280
00:18:10,338 --> 00:18:14,358
is stored. And for that we actually have a volume type

281
00:18:14,444 --> 00:18:17,666
called empty deer or empty directory.

282
00:18:17,778 --> 00:18:21,986
And empty directory volume is perfect for multicontainer

283
00:18:22,018 --> 00:18:25,914
pods. The empty Deere volume will only be accessible for

284
00:18:25,952 --> 00:18:30,406
the pod and its containers, and can be shared among its containers.

285
00:18:30,518 --> 00:18:34,810
And as the name suggests, the empty deer volume will be empty whenever

286
00:18:34,890 --> 00:18:37,966
pod restarts. So it always starts from the

287
00:18:37,988 --> 00:18:40,974
scratch, and then containers can update the data inside.

288
00:18:41,092 --> 00:18:45,120
And configuring that is also very easy. Let's see how it works.

289
00:18:47,830 --> 00:18:51,394
First of all, for empty deer volume type, we do not

290
00:18:51,432 --> 00:18:55,262
need a persistent volume or persistent volume claim components.

291
00:18:55,406 --> 00:18:59,042
We can define that directly into the pod, because again,

292
00:18:59,096 --> 00:19:02,982
it's not a persistent volume, it's just used to share data

293
00:19:03,116 --> 00:19:06,294
among the containers. However, defining them

294
00:19:06,332 --> 00:19:09,766
in the pod is actually pretty much the same. Let's give us some

295
00:19:09,788 --> 00:19:13,370
space here and on the same level as containers,

296
00:19:13,870 --> 00:19:18,746
we're going to define volumes again and

297
00:19:18,768 --> 00:19:21,740
let's give it a name, call it lock data.

298
00:19:22,190 --> 00:19:25,626
And the last time when we referenced persistent

299
00:19:25,658 --> 00:19:29,406
volume claim, we had a persistent volume claim attribute here.

300
00:19:29,508 --> 00:19:33,310
For empty deer, we have an empty deer attribute,

301
00:19:33,810 --> 00:19:37,582
and the only configuration we need for empty deer attribute

302
00:19:37,646 --> 00:19:41,218
is empty curly braces. That's it.

303
00:19:41,304 --> 00:19:45,266
So that configures a volume for the pod. And now we can

304
00:19:45,368 --> 00:19:48,650
pass that volume to the containers. And the same way we're

305
00:19:48,670 --> 00:19:50,710
going to define volume mounts,

306
00:19:53,770 --> 00:19:57,640
the name will reference the volume name defined here,

307
00:19:58,410 --> 00:20:02,326
and we have the same mount path attribute. And let's

308
00:20:02,358 --> 00:20:06,454
say this is going to be on Varlock

309
00:20:06,502 --> 00:20:09,914
path inside the container and we

310
00:20:09,952 --> 00:20:13,946
can grab that exact configuration and configure

311
00:20:13,978 --> 00:20:17,214
it for the sidecar container. So basically what

312
00:20:17,252 --> 00:20:21,274
this does is it creates a shared volume for both containers

313
00:20:21,402 --> 00:20:25,070
and then it mounts that shared volume into each

314
00:20:25,140 --> 00:20:29,298
container at this path. So this path is actually inside

315
00:20:29,384 --> 00:20:33,230
the container. And as I said, the other containers

316
00:20:33,310 --> 00:20:36,398
cannot access file system of another container.

317
00:20:36,494 --> 00:20:40,546
However, what can happen now is that whenever main application writes

318
00:20:40,578 --> 00:20:44,630
something to this location, it will get propagated to this

319
00:20:44,700 --> 00:20:48,434
shared volume of MTDR type. And then whatever gets written

320
00:20:48,482 --> 00:20:52,470
here gets propagated back to another container

321
00:20:52,630 --> 00:20:56,486
and will be visible inside here. So a sitecore

322
00:20:56,518 --> 00:20:59,610
container can now read the data that main application

323
00:20:59,760 --> 00:21:03,778
wrote to this location. And also note that the mount

324
00:21:03,814 --> 00:21:07,950
path can be totally different on

325
00:21:08,020 --> 00:21:11,534
each container. It doesn't have to be the same as long as they are

326
00:21:11,572 --> 00:21:15,306
referencing the same empty deer volume. And let's

327
00:21:15,338 --> 00:21:17,220
actually test that this works.

328
00:21:19,910 --> 00:21:24,110
So what I'm going to do is I'm going to simulate the NginX container

329
00:21:24,190 --> 00:21:27,810
writing some data into that location

330
00:21:28,410 --> 00:21:32,194
like this. So basically every 5 seconds

331
00:21:32,322 --> 00:21:36,870
it writes this line into Varlog

332
00:21:37,690 --> 00:21:41,598
myapp log file. And with these two greater than signs

333
00:21:41,634 --> 00:21:45,206
it basically just appends every line to that log file.

334
00:21:45,318 --> 00:21:49,402
And on the other hand, let's say we want to access whatever

335
00:21:49,536 --> 00:21:53,426
main application has written here inside the sidecar

336
00:21:53,558 --> 00:21:54,240
application.

337
00:21:57,570 --> 00:22:00,846
So for that, let's actually delete this and

338
00:22:01,028 --> 00:22:05,038
tail the file contents of MyApp log.

339
00:22:05,204 --> 00:22:08,674
Now inside the sidecar container, this will be actually at this

340
00:22:08,792 --> 00:22:11,250
path because that's where we're mounting it.

341
00:22:11,400 --> 00:22:14,626
And the name of the file will be

342
00:22:14,808 --> 00:22:18,606
Myapp log. So let's see that in action.

343
00:22:18,718 --> 00:22:22,706
I'm going to save this. Okay, so the Internet's deployment

344
00:22:22,738 --> 00:22:26,774
pod is running. Let's now actually check the logs to see that

345
00:22:26,892 --> 00:22:30,914
the sitecar container was able to access the log file

346
00:22:30,962 --> 00:22:34,266
that the main application has written into.

347
00:22:34,448 --> 00:22:37,814
So logs

348
00:22:37,862 --> 00:22:41,658
and we have to specify the container name, which is

349
00:22:41,824 --> 00:22:45,646
log sitecar. And as you

350
00:22:45,668 --> 00:22:50,254
see, we have the date of

351
00:22:50,292 --> 00:22:54,062
the log. Then we have info and some app data, which is

352
00:22:54,116 --> 00:22:58,378
exactly what the main application is logging every 5 seconds

353
00:22:58,554 --> 00:23:01,970
and which the sidecar application was able

354
00:23:02,040 --> 00:23:05,458
to access and then print out. That's how you

355
00:23:05,464 --> 00:23:09,730
can use a shared storage location among containers

356
00:24:34,760 --> 00:24:38,600
that is running in a cluster needs to connect to

357
00:24:38,670 --> 00:24:41,976
a database and some other services. Now all of

358
00:24:41,998 --> 00:24:45,856
these services need credentials to connect to like username

359
00:24:45,908 --> 00:24:49,484
and password or secret token. So developers ask

360
00:24:49,522 --> 00:24:53,212
you, what is the best way to create and pass an

361
00:24:53,266 --> 00:24:56,364
external configuration with credentials to

362
00:24:56,402 --> 00:25:00,252
the applications in Kubernetes? And that's where secret

363
00:25:00,316 --> 00:25:03,836
and config map resources come in. So let's

364
00:25:03,868 --> 00:25:07,664
see how this works. First, as you learned, secret is

365
00:25:07,702 --> 00:25:11,492
for sensitive configuration data, while configmap is for

366
00:25:11,546 --> 00:25:15,380
regular configuration data. Now this configuration data

367
00:25:15,530 --> 00:25:19,236
from configmap or secret can be passed to

368
00:25:19,258 --> 00:25:23,040
the applications in the pod in two different ways,

369
00:25:23,210 --> 00:25:27,828
either as individual values using environment variables,

370
00:25:28,004 --> 00:25:32,148
or as configuration files using volumes.

371
00:25:32,244 --> 00:25:35,788
And we will see examples of both of these ways in the next

372
00:25:35,874 --> 00:25:37,100
demo section.

373
00:26:30,240 --> 00:26:33,676
Config map and secret components. And then

374
00:26:33,698 --> 00:26:37,176
we're going to pass the data inside to the pod

375
00:26:37,288 --> 00:26:39,420
using environment variables.

376
00:26:42,020 --> 00:26:46,268
And for that I'm actually going to create a folder and I'm

377
00:26:46,284 --> 00:26:48,400
going to call this external config.

378
00:26:51,540 --> 00:26:54,740
And let's create my config map.

379
00:26:55,400 --> 00:27:01,376
Yaml first and let's call it myappconfig.

380
00:27:01,488 --> 00:27:05,008
And the specification is actually super simple. We define

381
00:27:05,104 --> 00:27:08,264
data attribute, and under the data attribute we have

382
00:27:08,302 --> 00:27:11,944
a list of key value pairs which can specify any

383
00:27:11,982 --> 00:27:15,704
service endpoints that your application needs to connect to,

384
00:27:15,742 --> 00:27:19,470
for example or any other type of configuration for your application.

385
00:27:19,840 --> 00:27:23,480
And in our case, let's say we want to specify just a database

386
00:27:23,560 --> 00:27:26,700
endpoint. Let's call it DB host,

387
00:27:27,120 --> 00:27:31,410
which is the key. The syntax for the key can be anything,

388
00:27:33,220 --> 00:27:36,864
it could be lowercase, uppercase, doesn't really matter, that's up to you to

389
00:27:36,902 --> 00:27:41,036
decide and the actual value. And let's say in our case that's Mysql

390
00:27:41,068 --> 00:27:44,868
service and that's our config map. As simple as that.

391
00:27:45,034 --> 00:27:46,390
So let's save it.

392
00:27:50,120 --> 00:27:53,504
And as a next step, let's create my secret.

393
00:27:53,632 --> 00:27:56,260
So that's going to be my app secret.

394
00:27:56,420 --> 00:27:59,364
And again, super simple configuration.

395
00:27:59,492 --> 00:28:02,904
First we need a type because we have different types of

396
00:28:02,942 --> 00:28:06,392
secrets in kubernetes. One of them we already saw

397
00:28:06,446 --> 00:28:09,996
was service account type. And this one is basically

398
00:28:10,098 --> 00:28:13,960
a general type that you can use for secret configuration.

399
00:28:14,120 --> 00:28:17,484
So type opaque. And then we have the same

400
00:28:17,522 --> 00:28:21,308
data attribute, which again

401
00:28:21,474 --> 00:28:26,032
is a list of key value pairs with

402
00:28:26,086 --> 00:28:28,896
arbitrary values. However,

403
00:28:28,998 --> 00:28:32,976
note that the value has to be base 64 encoded.

404
00:28:33,088 --> 00:28:37,620
We can't just put in plain text

405
00:28:37,690 --> 00:28:41,072
here, right? So let's define

406
00:28:41,136 --> 00:28:45,368
password and username. And I'm going to switch to another

407
00:28:45,454 --> 00:28:49,588
terminal and let's create a base 64 encoded

408
00:28:49,684 --> 00:28:53,524
text here, which is super simple. You just do echo

409
00:28:53,652 --> 00:28:57,660
and then n, which is very important for

410
00:28:57,730 --> 00:29:01,532
considering the end of the line and then your

411
00:29:01,586 --> 00:29:04,988
text that you want to encode, right? So for example,

412
00:29:05,074 --> 00:29:08,876
this could be my user and then

413
00:29:08,898 --> 00:29:13,170
my base 64 encoded like this and

414
00:29:14,980 --> 00:29:17,970
my password like this.

415
00:29:19,380 --> 00:29:22,852
So that's the base 64 encoded value. So I'm going to copy that,

416
00:29:22,986 --> 00:29:27,184
paste it in here, same for the password

417
00:29:27,312 --> 00:29:30,932
and that's it. Let's save it. So we have our

418
00:29:30,986 --> 00:29:34,790
config map and secret. Now we can actually apply that

419
00:29:35,980 --> 00:29:40,132
to apply multiple files at once. You can actually just specify

420
00:29:40,276 --> 00:29:44,500
the current directory so everything in that directory will be applied,

421
00:29:44,660 --> 00:29:48,392
which in our case we just have two files in this directory.

422
00:29:48,456 --> 00:29:51,070
So let's execute. And there you go.

423
00:29:53,640 --> 00:29:56,496
So now that we have these two components,

424
00:29:56,608 --> 00:30:00,352
let's create a deployment that uses values

425
00:30:00,416 --> 00:30:03,656
from the secret and config map. Again,

426
00:30:03,758 --> 00:30:08,788
I'm going to create MyApp deployment Yaml

427
00:30:08,964 --> 00:30:13,024
and I'm going to paste in a base deployment

428
00:30:13,092 --> 00:30:16,376
configuration. Alternatively, you can also generate

429
00:30:16,408 --> 00:30:20,172
this from Kubectl create deployment command as you

430
00:30:20,226 --> 00:30:23,436
already learned, and then basically just open it and

431
00:30:23,458 --> 00:30:27,260
edit it. So this is a base configuration.

432
00:30:27,340 --> 00:30:30,892
Now we need to use the values from secret

433
00:30:30,956 --> 00:30:34,704
and config map in this application and

434
00:30:34,742 --> 00:30:38,220
we're going to reference them using environment variables.

435
00:30:38,380 --> 00:30:42,016
You already learned how to define environment variables on a

436
00:30:42,038 --> 00:30:45,316
pod, so this is going to be the same concept. We have

437
00:30:45,338 --> 00:30:49,316
the name of the environment variable, which we can decide what it's going to be.

438
00:30:49,418 --> 00:30:52,968
Let's call this MysQl user and

439
00:30:53,134 --> 00:30:56,708
the value either hard coded like my user,

440
00:30:56,884 --> 00:31:00,664
or if we are referencing and using that value from a

441
00:31:00,702 --> 00:31:04,508
secret, then we're going to do value from

442
00:31:04,674 --> 00:31:08,110
and use a secret key

443
00:31:08,560 --> 00:31:12,588
reference. So that's the attribute name.

444
00:31:12,754 --> 00:31:16,316
And inside that secret key reference we have the name of

445
00:31:16,338 --> 00:31:20,684
the secret my

446
00:31:20,722 --> 00:31:24,928
app secret and the key of the value

447
00:31:25,014 --> 00:31:28,516
that we want to get from the secret. And we called it

448
00:31:28,538 --> 00:31:32,340
username. So whatever we defined as a value of

449
00:31:32,490 --> 00:31:36,528
username inside my app secret will be substituted

450
00:31:36,624 --> 00:31:39,824
right here as a value for MysQl user

451
00:31:39,872 --> 00:31:43,080
environment variable. And let's do the same

452
00:31:43,150 --> 00:31:46,360
for password.

453
00:31:47,340 --> 00:31:51,880
Let's call the environment variable mysql pwd value

454
00:31:51,950 --> 00:31:59,404
from and actually I can just copy this and

455
00:31:59,522 --> 00:32:03,740
it's the same secret but key name is password.

456
00:32:05,860 --> 00:32:09,200
And we have one more value want to use here

457
00:32:09,270 --> 00:32:11,970
from config map. So again,

458
00:32:12,980 --> 00:32:16,960
name of the environment variable, let's call this MySQl server

459
00:32:17,460 --> 00:32:21,444
value from because

460
00:32:21,482 --> 00:32:25,124
we are referencing another component instead of defining it

461
00:32:25,162 --> 00:32:28,928
here directly and instead of secrets key ref it's

462
00:32:28,944 --> 00:32:33,236
going to be config map key reference

463
00:32:33,428 --> 00:32:36,120
and we have the same name attribute,

464
00:32:37,020 --> 00:32:40,136
myapp config, that's what

465
00:32:40,158 --> 00:32:44,296
we called it. And key inside the config map

466
00:32:44,488 --> 00:32:48,764
which is Db underscore host. Now very

467
00:32:48,802 --> 00:32:52,524
important to note here, you don't have to memorize the

468
00:32:52,562 --> 00:32:56,124
syntax for each such configuration by heart

469
00:32:56,242 --> 00:32:59,564
because you can always look them up in a documentation.

470
00:32:59,692 --> 00:33:03,644
You will probably memorize and learn by heart the configuration

471
00:33:03,692 --> 00:33:07,296
for the most common things that you do all the time.

472
00:33:07,398 --> 00:33:11,444
But this kind of syntax you can always just check in the documentation. So this

473
00:33:11,482 --> 00:33:15,248
configures our application with the environment variables

474
00:33:15,344 --> 00:33:19,120
that reference data from secret and config map

475
00:33:19,200 --> 00:33:22,984
components. Now let's also add a command here to make

476
00:33:23,022 --> 00:33:27,384
sure that the values are actually being set and

477
00:33:27,422 --> 00:33:31,000
let's just simply print them out. So I'm going to do command

478
00:33:33,600 --> 00:33:39,612
sh shell and

479
00:33:39,746 --> 00:33:43,692
I'm simply going to do print env and basically just

480
00:33:43,746 --> 00:33:47,164
print the values of all these environment

481
00:33:47,212 --> 00:33:50,112
variables. So this is going to simply print them out.

482
00:33:50,246 --> 00:33:53,744
And as you already know, containers are

483
00:33:53,782 --> 00:33:57,568
there to execute specific tasks and when the task is done,

484
00:33:57,654 --> 00:34:01,044
container will exit and we don't want that. So let's add

485
00:34:01,082 --> 00:34:04,404
a sleep command here so that container stays running for

486
00:34:04,442 --> 00:34:10,576
a bit and let's save it and

487
00:34:10,698 --> 00:34:14,168
apply. Note that the

488
00:34:14,254 --> 00:34:18,020
secret and config map that you're referencing in your deployment

489
00:34:18,100 --> 00:34:21,204
configuration need to already exist in the cluster

490
00:34:21,332 --> 00:34:24,824
before you create the deployment. Otherwise you will get an error

491
00:34:24,872 --> 00:34:27,230
that it can't find them.

492
00:34:28,160 --> 00:34:31,740
And kubectl get pod and we should see our application

493
00:34:31,890 --> 00:34:34,476
is running, which is this one right here.

494
00:34:34,658 --> 00:34:39,904
And now let's actually log the

495
00:34:39,942 --> 00:34:43,900
pod to see the environment variable values.

496
00:34:43,980 --> 00:34:47,650
So we have my user, my PWD MySQl service.

497
00:34:48,040 --> 00:34:51,680
So the values of secret and config map

498
00:34:51,760 --> 00:34:55,312
components were successfully extracted

499
00:34:55,376 --> 00:34:58,692
and passed over to our pod as

500
00:34:58,746 --> 00:35:01,992
environment variables. And this will actually be a very

501
00:35:02,046 --> 00:35:06,244
common use case for developers to configure

502
00:35:06,292 --> 00:35:09,736
some external configuration using config map and secret and

503
00:35:09,758 --> 00:35:13,000
then use that in the deployment configuration

504
00:36:11,140 --> 00:36:14,944
configuration is actually not just a piece of data like

505
00:36:15,062 --> 00:36:19,088
username or password or some secret token, but rather

506
00:36:19,174 --> 00:36:22,836
a whole configuration file. For example, for a

507
00:36:22,858 --> 00:36:26,432
MySQl application you may want to define

508
00:36:26,496 --> 00:36:29,908
an external configuration file with lots of data inside,

509
00:36:29,994 --> 00:36:33,696
right? Or you may want to pass in a configuration file

510
00:36:33,728 --> 00:36:37,396
to your application that contains some credentials

511
00:36:37,428 --> 00:36:41,124
as well. So passing those as individual values

512
00:36:41,172 --> 00:36:45,016
like these will not be an option here. So the

513
00:36:45,038 --> 00:36:49,084
question is how can we create configuration files for

514
00:36:49,122 --> 00:36:52,728
applications and then pass them to the pod configuration?

515
00:36:52,824 --> 00:36:56,392
Well, we can do that also using config map and secret.

516
00:36:56,536 --> 00:36:57,950
Let's see how it works.

517
00:37:00,900 --> 00:37:03,968
Using config map and secret we can actually

518
00:37:04,054 --> 00:37:08,172
create files instead of just defining key value pairs.

519
00:37:08,236 --> 00:37:12,980
So I'm going to create my config map file yaml

520
00:37:14,120 --> 00:37:18,720
and again, same configuration

521
00:37:18,880 --> 00:37:22,516
and same data attribute. Now instead of

522
00:37:22,538 --> 00:37:26,596
defining key value pairs here, I'm going to define

523
00:37:26,788 --> 00:37:30,490
name of the file, let's call it Mysql conf.

524
00:37:31,420 --> 00:37:34,936
So that's going to be the key name, so to say.

525
00:37:35,118 --> 00:37:38,316
And as a value I'm going to define the

526
00:37:38,338 --> 00:37:42,028
whole file. And the syntax for that in Yaml is

527
00:37:42,114 --> 00:37:45,724
the pipe. So basically pipe will let you

528
00:37:45,762 --> 00:37:49,644
define a multiline string. So basically this

529
00:37:49,682 --> 00:37:52,704
will give us the same key value pair but as a

530
00:37:52,742 --> 00:37:56,896
file with the name of the file as key and the contents of the

531
00:37:56,918 --> 00:38:01,420
file as the value. And here you can define the

532
00:38:01,590 --> 00:38:05,104
MySQl configuration as you normally

533
00:38:05,152 --> 00:38:09,296
would like this. And this is actually a valid MySQl

534
00:38:09,328 --> 00:38:12,592
configuration. And also know that you can define

535
00:38:12,656 --> 00:38:15,876
multiple such files. So you can have

536
00:38:15,978 --> 00:38:19,304
another file conf and

537
00:38:19,422 --> 00:38:22,664
again have another file contents. So you can have

538
00:38:22,702 --> 00:38:26,890
a list of files here and let's save it.

539
00:38:30,240 --> 00:38:33,752
And same way you can define secret

540
00:38:33,816 --> 00:38:37,928
file, let's call it secret

541
00:38:38,104 --> 00:38:41,040
file as well, the same data attribute,

542
00:38:42,100 --> 00:38:45,936
secret file as

543
00:38:45,958 --> 00:38:49,404
a name and the file contents.

544
00:38:49,532 --> 00:38:53,476
And again the contents of the file has to

545
00:38:53,498 --> 00:38:57,184
be base 64 encoded. So again I'm going to switch

546
00:38:57,232 --> 00:39:00,784
here. And we actually have installation

547
00:39:00,832 --> 00:39:04,536
files here. So you can actually base 64, encode the

548
00:39:04,558 --> 00:39:08,504
whole file and then set its

549
00:39:08,622 --> 00:39:11,944
value right here. And we can try to

550
00:39:11,982 --> 00:39:15,770
do that. And let's trim all those new lines first

551
00:39:19,360 --> 00:39:23,372
like this, so we can copy and

552
00:39:23,426 --> 00:39:27,292
that's going to be the secret file content. Let's save

553
00:39:27,346 --> 00:39:30,816
it. And now let's see how

554
00:39:30,838 --> 00:39:34,336
we can reference those configuration files inside the

555
00:39:34,358 --> 00:39:35,760
pod specification.

556
00:39:38,900 --> 00:39:43,380
So I'm going to create a new pod definition, let's call this myapp

557
00:39:43,800 --> 00:39:46,980
deployment file.

558
00:39:48,840 --> 00:39:52,436
And again I'm going to copy in the file and this is

559
00:39:52,458 --> 00:39:55,956
going to simulate a MySQL database pod because we created MySQL

560
00:39:55,988 --> 00:39:59,716
configuration which we want to pass in as a configuration and we're

561
00:39:59,748 --> 00:40:03,752
using just simple busybox image for that. So in order to

562
00:40:03,886 --> 00:40:07,168
configure files defined in configmap

563
00:40:07,204 --> 00:40:11,144
and secret as configuration files in your pod,

564
00:40:11,272 --> 00:40:14,824
we're going to use volumes. So config map

565
00:40:14,872 --> 00:40:19,236
and secret are actually types of volumes. They're not persistent

566
00:40:19,288 --> 00:40:22,796
volume types, but they are actually one of the volume types

567
00:40:22,908 --> 00:40:26,892
that lets you define inside config map or secret

568
00:40:27,036 --> 00:40:30,860
into the containers. And we already learned

569
00:40:31,020 --> 00:40:34,304
how volume configuration

570
00:40:34,352 --> 00:40:37,872
is defined. So we have volumes in the pod

571
00:40:37,936 --> 00:40:41,204
specification. We have name

572
00:40:41,242 --> 00:40:44,160
of the volume, let's call this db config.

573
00:40:44,320 --> 00:40:47,432
And the second attribute of the volume is always the

574
00:40:47,486 --> 00:40:50,740
type of the volume, right? We already saw empty deer

575
00:40:50,820 --> 00:40:55,560
and persistent volume claim. In our case we have config map

576
00:40:56,800 --> 00:41:00,296
and of course we need name of that config

577
00:41:00,328 --> 00:41:04,620
map, which we called MySQL config file.

578
00:41:05,760 --> 00:41:08,860
And we also have to reference the secret,

579
00:41:09,780 --> 00:41:13,490
let's call it db secret. And type

580
00:41:13,940 --> 00:41:18,172
is secret and this one actually has secret

581
00:41:18,236 --> 00:41:22,210
name as an attribute and

582
00:41:22,520 --> 00:41:26,432
MySQL secret file.

583
00:41:26,576 --> 00:41:30,048
Again, you can look up the syntax for this and you don't

584
00:41:30,064 --> 00:41:33,056
have to remember exactly the attribute names,

585
00:41:33,168 --> 00:41:36,512
but it's important to remember that when you define volumes,

586
00:41:36,576 --> 00:41:40,104
you first define them on a pod level, and then for

587
00:41:40,142 --> 00:41:43,992
each volume you create or you give it a name and the type

588
00:41:44,046 --> 00:41:48,044
of the volume with its specification, and after that you

589
00:41:48,162 --> 00:41:51,756
mount that volume into the container using

590
00:41:51,858 --> 00:41:55,276
volume mounts attribute, referencing the

591
00:41:55,298 --> 00:41:58,380
name of the volume and mount path.

592
00:41:59,120 --> 00:42:02,720
And let's say the configuration file from

593
00:42:02,870 --> 00:42:09,360
here goes to dbconfig

594
00:42:10,180 --> 00:42:13,712
or whatever the default MySQL configuration

595
00:42:13,776 --> 00:42:17,684
is. You can also define that instead. And we

596
00:42:17,722 --> 00:42:23,024
have another volume

597
00:42:23,072 --> 00:42:27,192
mount in the same container which

598
00:42:27,246 --> 00:42:30,600
we can mount into another location,

599
00:42:30,940 --> 00:42:34,116
Mysql dB secret.

600
00:42:34,228 --> 00:42:37,924
So these two are the attributes always used in volume mounts.

601
00:42:37,972 --> 00:42:41,948
And we have third attribute here which defines whether

602
00:42:42,114 --> 00:42:45,596
the data that we mount here is read only or

603
00:42:45,618 --> 00:42:49,116
not. By default it's not read only, so the application can

604
00:42:49,138 --> 00:42:52,432
actually make changes to whatever we pass here.

605
00:42:52,566 --> 00:42:55,936
However, let's say this is a secret file that is not supposed to

606
00:42:55,958 --> 00:42:59,936
be changed or adjusted. So to make sure the

607
00:42:59,958 --> 00:43:03,812
application doesn't accidentally, somehow rewrite the data,

608
00:43:03,946 --> 00:43:06,740
we're going to set it to read only. True.

609
00:43:06,890 --> 00:43:10,580
And finally, to make sure everything

610
00:43:10,650 --> 00:43:14,630
was configured correctly, let's just print out

611
00:43:15,980 --> 00:43:23,176
the file contents and

612
00:43:23,198 --> 00:43:27,130
for that I'm simply going to cat

613
00:43:27,680 --> 00:43:29,740
both of the file contents.

614
00:43:31,680 --> 00:43:35,640
And again, let's sleep for 20 seconds.

615
00:43:35,800 --> 00:43:39,444
So that's the configuration for creating

616
00:43:39,512 --> 00:43:43,452
and then passing configuration files instead of configuration

617
00:43:43,516 --> 00:43:47,456
values from config map and secret to the application.

618
00:43:47,638 --> 00:43:51,136
Now there's one important thing here to understand

619
00:43:51,318 --> 00:43:54,468
that the mount path is actually a folder name,

620
00:43:54,554 --> 00:43:58,036
right? So we want to reference the files or we want

621
00:43:58,058 --> 00:44:02,196
to actually print out the file contents inside

622
00:44:02,298 --> 00:44:05,412
that folder name. The way it works is that any

623
00:44:05,466 --> 00:44:09,144
files defined in a config map will

624
00:44:09,182 --> 00:44:12,936
be actually mounted into this folder. So if

625
00:44:12,958 --> 00:44:16,900
we had multiple files or key value attributes defined

626
00:44:16,980 --> 00:44:20,732
in the config map, we would have all of those files actually

627
00:44:20,786 --> 00:44:24,232
in this folder. And same goes for a secret.

628
00:44:24,376 --> 00:44:27,756
And the files will be named the same as we name them in

629
00:44:27,778 --> 00:44:31,664
the config map definition. And that means to

630
00:44:31,702 --> 00:44:35,420
print the file we're going to do dbconfig

631
00:44:35,580 --> 00:44:39,264
MySql conf and the secret file name is

632
00:44:39,382 --> 00:44:43,264
secret file because that's how

633
00:44:43,302 --> 00:44:46,724
we named it. So again, the files will be stored in this

634
00:44:46,762 --> 00:44:50,544
directory in the mount path with a name that we define

635
00:44:50,672 --> 00:44:54,996
as the key inside config map or secret configuration.

636
00:44:55,108 --> 00:44:58,776
So let's save this. And now that we have all the

637
00:44:58,798 --> 00:45:02,056
files ready, let's actually apply them one by one.

638
00:45:02,158 --> 00:45:05,160
First let's create the my config file,

639
00:45:08,000 --> 00:45:09,660
let's create the secret,

640
00:45:11,680 --> 00:45:15,500
and finally let's apply the deployment.

641
00:45:21,380 --> 00:45:24,400
So let's check that our pod is running. And there you go.

642
00:45:24,550 --> 00:45:27,664
And let's log it to

643
00:45:27,702 --> 00:45:31,680
see that files were configured correctly.

644
00:45:32,600 --> 00:45:35,748
Execute. And there you go. So first of

645
00:45:35,754 --> 00:45:39,476
all, we have the config map file contents, which was

646
00:45:39,578 --> 00:45:43,632
these five lines here, and this is actually the secret

647
00:45:43,696 --> 00:45:48,036
file install shell

648
00:45:48,068 --> 00:45:51,336
script actually that we configured as a

649
00:45:51,358 --> 00:45:55,624
value in the secret. So they were passed as

650
00:45:55,822 --> 00:45:59,644
configuration files in the pod and we were able to

651
00:45:59,762 --> 00:46:02,140
see the print out the contents.

652
00:46:05,680 --> 00:46:09,256
And finally, another very important thing to

653
00:46:09,378 --> 00:46:12,912
remember about external configuration with

654
00:46:12,966 --> 00:46:16,512
config maps and secret in Kubernetes is that whenever we

655
00:46:16,566 --> 00:46:19,616
update the contents of config map or a

656
00:46:19,638 --> 00:46:23,408
secret, the pods that reference this config map

657
00:46:23,424 --> 00:46:26,868
or secret data do not automatically get

658
00:46:27,034 --> 00:46:30,916
the up to date information. They will still see the

659
00:46:30,938 --> 00:46:34,448
old configuration. So in order to make the changes

660
00:46:34,554 --> 00:46:38,216
effective, to basically reload the configuration in the pod, we will

661
00:46:38,238 --> 00:46:41,784
have to restart the pod. So to see that, let's say

662
00:46:41,822 --> 00:46:45,764
we changed our secret file

663
00:46:45,812 --> 00:46:55,484
configuration and

664
00:46:55,522 --> 00:46:58,668
let's say we defined it to be some other value,

665
00:46:58,754 --> 00:47:02,236
right? This is a new secret

666
00:47:02,348 --> 00:47:12,392
file database

667
00:47:12,476 --> 00:47:16,020
and we basically updated the existing secret.

668
00:47:16,680 --> 00:47:19,924
Now as you see, the pod doesn't get restarted as

669
00:47:19,962 --> 00:47:24,704
well as it doesn't get the changes in the secret data automatically.

670
00:47:24,832 --> 00:47:28,744
For that we would have to restart all the pods that reference that

671
00:47:28,862 --> 00:47:32,516
secret or config map. Now one way to restart the pods

672
00:47:32,548 --> 00:47:36,040
is basically doing Kubectl delete and the pod name. However,

673
00:47:36,110 --> 00:47:39,996
if you have multiple pod replicas and if you want to restart all of

674
00:47:40,018 --> 00:47:44,440
them, to get the new secret or config map configuration,

675
00:47:44,600 --> 00:47:48,664
you can use command called Kubectl rollout

676
00:47:48,792 --> 00:47:52,492
restart. So Kubectl rollout

677
00:47:52,556 --> 00:47:56,124
restart allows you to restart

678
00:47:56,252 --> 00:48:00,508
deployment or stateful set and all its pods.

679
00:48:00,604 --> 00:48:04,724
So in our case, deployment name is MyDB and

680
00:48:04,762 --> 00:48:08,720
if I execute this it will terminate the old pod

681
00:48:08,800 --> 00:48:12,832
and start a new one again. If you had ten replicas

682
00:48:12,976 --> 00:48:16,056
of MyDB deployment, all the pods will be

683
00:48:16,078 --> 00:48:19,576
restarted one by one. And you can also check the

684
00:48:19,678 --> 00:48:22,920
status of your rollout restart

685
00:48:23,420 --> 00:48:26,664
using rollout status. In this case

686
00:48:26,702 --> 00:48:30,620
you see that it was successfully rolled out, so it's completed.

687
00:48:31,120 --> 00:48:34,696
And now let's check the logs

688
00:48:34,728 --> 00:48:35,310
again.

689
00:48:41,120 --> 00:48:44,956
It and as you see we got the new secret

690
00:48:44,988 --> 00:48:47,680
data inside the pod.

691
00:48:50,740 --> 00:48:54,548
As a Kubernetes administrator you check regularly whether

692
00:48:54,634 --> 00:48:57,840
developers are adhering to the best practice

693
00:48:57,920 --> 00:49:01,616
standards and configuring workloads correctly.

694
00:49:01,728 --> 00:49:05,240
So as one of those best practices, you want to check

695
00:49:05,390 --> 00:49:09,544
whether they have defined resource requests and limits for

696
00:49:09,582 --> 00:49:13,252
their workloads. So first let's understand what resource

697
00:49:13,316 --> 00:49:16,776
requests and limits are in Kubernetes, and then

698
00:49:16,798 --> 00:49:20,456
let's see how to use them in the application configuration

699
00:49:20,568 --> 00:49:24,060
so that when you see workloads configured without them,

700
00:49:24,130 --> 00:49:28,060
you can send the developers a corrected YaML file example

701
00:49:28,210 --> 00:49:31,488
to use as a sample and also explain

702
00:49:31,574 --> 00:49:35,232
to them how they can define how much resources their

703
00:49:35,286 --> 00:49:39,730
pods may require and explain to them how it all works.

704
00:49:43,330 --> 00:49:47,738
Some applications may need more cpu and memory resources

705
00:49:47,834 --> 00:49:51,630
than others, so to make sure that your application container has

706
00:49:51,700 --> 00:49:55,290
enough resources when it starts inside the pod,

707
00:49:55,370 --> 00:49:58,882
you should define resource requests for each of your

708
00:49:58,936 --> 00:49:59,890
containers.

709
00:50:03,080 --> 00:50:07,264
And with this defined, your containers will have enough resources

710
00:50:07,312 --> 00:50:10,864
to consume. But what if while the container is

711
00:50:10,922 --> 00:50:14,984
running, it actually needs more than what it

712
00:50:15,022 --> 00:50:18,472
requested in resources? So what if it goes over

713
00:50:18,526 --> 00:50:22,552
limits? So to say, for example, this can happen if one application gets

714
00:50:22,606 --> 00:50:25,992
too much data that it needs to load into memory,

715
00:50:26,056 --> 00:50:29,896
or application has a bug inside with some infinite loop

716
00:50:29,928 --> 00:50:33,880
and starts consuming all the cpu available on that node.

717
00:50:33,960 --> 00:50:38,172
In this case, one single container will actually start consuming

718
00:50:38,316 --> 00:50:41,868
more than the requested resources,

719
00:50:41,964 --> 00:50:46,156
and it can take all the cpu or memory of that node.

720
00:50:46,268 --> 00:50:50,004
So other pods running on the same node will not

721
00:50:50,042 --> 00:50:53,488
have enough resources, so they must be rescheduled.

722
00:50:53,584 --> 00:50:57,248
Of course, you want to avoid such situations where one container

723
00:50:57,344 --> 00:51:01,096
consumes all the resources on the node, and you can do

724
00:51:01,118 --> 00:51:05,140
that by setting resource limits for each container

725
00:51:05,220 --> 00:51:07,800
in addition to resource requests.

726
00:51:41,740 --> 00:51:45,484
Understand how resource requests and limits work and

727
00:51:45,522 --> 00:51:48,264
why you should use them in your pod configuration.

728
00:51:48,392 --> 00:51:52,460
Let's actually see their usage in practice. And to showcase that,

729
00:51:52,530 --> 00:51:56,690
let's actually reuse our NgINX deployment example

730
00:51:57,700 --> 00:52:01,372
with the sidecar container, and I'm going to create a new definition

731
00:52:01,436 --> 00:52:05,148
file for that. So we have the old copy unchanged,

732
00:52:05,244 --> 00:52:09,448
and let's call it NgInx deployment with resources

733
00:52:09,564 --> 00:52:13,616
Yaml. And we're going to define resource requests

734
00:52:13,648 --> 00:52:17,008
and limits on both containers inside the pod.

735
00:52:17,104 --> 00:52:21,664
So the first thing you need to decide is how much resources your applications

736
00:52:21,712 --> 00:52:25,512
are going to need. In most cases, you may have applications that

737
00:52:25,566 --> 00:52:29,220
just require an average amount of resources

738
00:52:29,300 --> 00:52:32,856
for cpu and ram, but you may have applications that

739
00:52:32,878 --> 00:52:36,856
are more cpu intensive. Or maybe you have a memory database

740
00:52:36,888 --> 00:52:40,972
like redis that obviously needs more memory space, right? And for them

741
00:52:41,026 --> 00:52:44,808
you would adjust the values and give them more cpu resources

742
00:52:44,904 --> 00:52:48,464
or more memory resources. So the main thing to understand here

743
00:52:48,502 --> 00:52:52,096
is that not all applications need the same amount of

744
00:52:52,198 --> 00:52:55,744
resources. And when they need significantly more or

745
00:52:55,782 --> 00:52:59,656
significantly less resources, it's always good to explicitly

746
00:52:59,708 --> 00:53:03,428
define them. So in our case, let's say that my app, the main

747
00:53:03,514 --> 00:53:07,408
web server application that runs with Nginx image

748
00:53:07,504 --> 00:53:11,196
let's say just needs an average amount of resources

749
00:53:11,248 --> 00:53:16,968
and we're going to define them in the container definition using

750
00:53:17,054 --> 00:53:21,400
resources attribute. And then we have requests and limits.

751
00:53:26,160 --> 00:53:29,772
Again, request is what you think your application will

752
00:53:29,826 --> 00:53:33,452
need to fulfill its job. So let's say we

753
00:53:33,506 --> 00:53:38,240
are expecting a memory usage of 64

754
00:53:38,310 --> 00:53:42,080
mi and cpu of

755
00:53:42,230 --> 00:53:45,484
250 m. So that's the expected

756
00:53:45,532 --> 00:53:49,344
usage. However, some applications have spikes

757
00:53:49,472 --> 00:53:52,724
and in that case they may actually require a little bit

758
00:53:52,762 --> 00:53:56,052
more resources. And again, to limit that

759
00:53:56,106 --> 00:53:59,888
maximum resource consumption, we are going to define

760
00:53:59,984 --> 00:54:03,352
limits memory, and let's say we

761
00:54:03,406 --> 00:54:07,636
allow twice as much resources

762
00:54:07,828 --> 00:54:11,640
and maximum for both cpu and memory

763
00:54:12,940 --> 00:54:17,384
like this. And the same way we're going to configure another container

764
00:54:17,512 --> 00:54:21,372
and we can actually copy this whole thing. And our

765
00:54:21,426 --> 00:54:25,224
logging sidecar application is much less cpu

766
00:54:25,272 --> 00:54:29,712
intensive so it doesn't actually require too much processing power

767
00:54:29,846 --> 00:54:33,376
to do its job. But let's say it stores a bunch of

768
00:54:33,398 --> 00:54:36,688
logs in the memory first before it sends them to an

769
00:54:36,694 --> 00:54:40,432
external logging service. So it requires more memory

770
00:54:40,496 --> 00:54:44,004
resources. And if we know that about our application, we can

771
00:54:44,042 --> 00:54:47,956
adjust it here so we can decide to give it 100

772
00:54:48,058 --> 00:54:52,840
m of cpu and 120

773
00:54:52,910 --> 00:54:56,808
mi for memory. And again, let's allow

774
00:54:56,974 --> 00:55:01,172
twice as much resources as a maximum limit.

775
00:55:01,316 --> 00:55:06,764
So this is going to be 256 and 200.

776
00:55:06,882 --> 00:55:10,492
And let's also change the name because we already

777
00:55:10,546 --> 00:55:13,740
have a MyApp deployment in the cluster.

778
00:55:14,160 --> 00:55:17,360
And let's actually apply our configuration.

779
00:55:21,220 --> 00:55:25,324
And there you go, we have MyApp resources pod

780
00:55:25,372 --> 00:55:29,750
running with the resource requirements explicitly set.

781
00:55:32,680 --> 00:55:35,972
Now if you had hundreds of deployments in the cluster and

782
00:55:36,026 --> 00:55:40,496
you wanted to check which pods have resource requirements

783
00:55:40,608 --> 00:55:43,880
explicitly defined, how would you actually list

784
00:55:43,950 --> 00:55:47,944
all this data? So we need a command that basically gives us

785
00:55:47,982 --> 00:55:51,864
a list of all the pods running in the cluster and next

786
00:55:51,902 --> 00:55:55,836
to it show us whether they have resource limits defined or

787
00:55:55,858 --> 00:56:00,088
not. And if they do, how much are those resource requirements?

788
00:56:00,184 --> 00:56:03,996
And that's going to be a very useful command to check

789
00:56:04,098 --> 00:56:07,724
that. Developers, for example, are deploying applications

790
00:56:07,852 --> 00:56:11,184
with the correct configuration. So let's see how we

791
00:56:11,222 --> 00:56:14,928
can get that output. And we're going

792
00:56:14,934 --> 00:56:18,696
to get that output using a JSON path output

793
00:56:18,748 --> 00:56:21,940
type, which as you remember, lets us pick

794
00:56:22,010 --> 00:56:25,296
specific values from the whole configuration

795
00:56:25,408 --> 00:56:29,024
using JSON path expressions. So let's do kubectl,

796
00:56:29,072 --> 00:56:33,144
get pod and then JSON path with

797
00:56:33,182 --> 00:56:36,056
an expression. So first of all,

798
00:56:36,078 --> 00:56:39,316
we want to iterate through all the pods. So we're going to define a range

799
00:56:39,348 --> 00:56:43,144
here of all the items like

800
00:56:43,182 --> 00:56:46,748
this. You already learned that. And for each item we're going

801
00:56:46,754 --> 00:56:50,300
to print out the name, and next to

802
00:56:50,370 --> 00:56:54,392
the name of the pod we're going to print out the resources

803
00:56:54,536 --> 00:56:58,352
configured, which is in spec

804
00:56:58,486 --> 00:57:01,836
specification containers. And for pods

805
00:57:01,868 --> 00:57:05,788
that have multiple containers, we want that resource definition for each container.

806
00:57:05,884 --> 00:57:10,256
So we're going to do all containers resources,

807
00:57:10,368 --> 00:57:14,612
and we want to separate each pod with a new line like

808
00:57:14,666 --> 00:57:19,204
this. So that's an expression that will give us a list of pods with

809
00:57:19,322 --> 00:57:22,836
the resource configurations. And there you

810
00:57:22,858 --> 00:57:26,184
go. We have five pods in this namespace, and for each

811
00:57:26,222 --> 00:57:29,768
pod we see whether they have a resource definition or not.

812
00:57:29,854 --> 00:57:32,952
So for some of them it is empty. And if you see two

813
00:57:33,006 --> 00:57:36,712
empty curly braces, it means this pod has two containers

814
00:57:36,776 --> 00:57:39,768
and none of them have defined resources.

815
00:57:39,864 --> 00:57:43,564
And then we have ingress Nginx controller that

816
00:57:43,602 --> 00:57:47,744
has resource request defined and it's resource configuration for

817
00:57:47,782 --> 00:57:48,960
both containers.

818
00:57:51,700 --> 00:57:55,884
Now an interesting note here is that when a node

819
00:57:56,012 --> 00:57:59,488
runs out of resources and has to evict

820
00:57:59,664 --> 00:58:03,540
one of the pods, it will actually evict the pods first

821
00:58:03,690 --> 00:58:07,680
that have no explicit resource definition.

822
00:58:07,760 --> 00:58:11,252
So that's basically how resource requests and limits work

823
00:58:11,306 --> 00:58:14,712
in Kubernetes, and why it is a good idea

824
00:58:14,766 --> 00:58:18,232
to always define them for the containers in your

825
00:58:18,286 --> 00:58:21,940
pods, as well as a command to inspect the whole cluster.

826
00:58:22,020 --> 00:58:25,660
For pods with no resource definitions,

827
00:58:28,860 --> 00:58:32,872
they have an application that runs some data and

828
00:58:32,926 --> 00:58:36,424
cpu intensive process. So they want to

829
00:58:36,462 --> 00:58:40,248
run pods belonging to this service on two dedicated

830
00:58:40,344 --> 00:58:43,852
nodes in the cluster where no other pods will run.

831
00:58:43,986 --> 00:58:47,516
So they will get all the resources. Plus they want

832
00:58:47,538 --> 00:58:52,376
to make sure only one pod replica of the same application runs

833
00:58:52,408 --> 00:58:55,804
on the same node. One of the developers also asks,

834
00:58:55,932 --> 00:58:59,660
how is it that no pods get scheduled on the master node?

835
00:58:59,740 --> 00:59:03,324
Because it's also part of the cluster nodes, right? And whether

836
00:59:03,382 --> 00:59:06,736
is it possible to schedule a regular pod on a master node

837
00:59:06,768 --> 00:59:10,084
as well? So you go ahead to find out all this

838
00:59:10,122 --> 00:59:10,710
information.

839
00:59:17,140 --> 00:59:20,864
Now, in Kubernetes we know that pods are automatically scheduled

840
00:59:20,912 --> 00:59:24,224
on one of the available worker nodes.

841
00:59:24,352 --> 00:59:27,584
Which node pod gets scheduled on is selected

842
00:59:27,632 --> 00:59:31,156
by the scheduler. And that's great because the scheduler has an

843
00:59:31,178 --> 00:59:34,596
intelligent way of deciding which node has the

844
00:59:34,618 --> 00:59:38,436
most capacity and is least busy to run a

845
00:59:38,458 --> 00:59:41,956
new pod process. But in some cases we may want to

846
00:59:41,978 --> 00:59:45,432
decide ourselves where the pod gets scheduled.

847
00:59:45,576 --> 00:59:49,276
So basically we can tell the scheduler, don't choose

848
00:59:49,378 --> 00:59:52,604
just any worker node for this pod, schedule it

849
00:59:52,642 --> 00:59:56,632
on this specific node, and we do that using an attribute

850
00:59:56,696 --> 00:59:59,530
called node name, and the value will be.

